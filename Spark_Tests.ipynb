{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def filter_spark_data_frame(dataframe,column_name='age',value=20):\n",
    "    return dataframe.where(col(column_name) > value)\n",
    "\n",
    "def test_filter_spark_data_frame_by_value():\n",
    "    # Spark Context initialisation\n",
    "    spark_context = SparkContext()\n",
    "    sql_context = SQLContext(spark_context)\n",
    "\n",
    "    # Input and output dataframes\n",
    "    input = sql_context.createDataFrame([('charly', 15),\n",
    "\n",
    "         ('fabien', 18),\n",
    "\n",
    "         ('sam', 21),\n",
    "\n",
    "         ('sam', 25),\n",
    "\n",
    "         ('nick', 19),\n",
    "\n",
    "         ('nick', 40)],\n",
    "\n",
    "        ['name', 'age'],\n",
    "\n",
    "    )\n",
    "\n",
    "    expected_output = sql_context.createDataFrame(\n",
    "\n",
    "        [('sam', 25),\n",
    "\n",
    "         ('sam', 21),\n",
    "\n",
    "         ('nick', 40)],\n",
    "\n",
    "        ['name', 'age'],\n",
    "\n",
    "    )\n",
    "\n",
    "    real_output = filter_spark_data_frame(input)\n",
    "\n",
    "    real_output = get_sorted_data_frame(\n",
    "\n",
    "        real_output.toPandas(),\n",
    "\n",
    "        ['age', 'name'],\n",
    "\n",
    "    )\n",
    "\n",
    "    expected_output = get_sorted_data_frame(\n",
    "\n",
    "        expected_output.toPandas(),\n",
    "\n",
    "        ['age', 'name'],\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # Equality assertion\n",
    "\n",
    "    pd.testing.assert_frame_equal(\n",
    "\n",
    "        expected_output,\n",
    "\n",
    "        real_output,\n",
    "\n",
    "        check_like=True,\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # Close the Spark Context\n",
    "\n",
    "    spark_context.stop()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_sorted_data_frame(data_frame, columns_list):\n",
    "\n",
    "    return data_frame.sort_values(columns_list).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark1 = SparkSession.builder.appName('Ops').getOrCreate()\n",
    "df = spark1.read.csv('ZA5524_3.csv', inferSchema=True, header=False)\n",
    "df.printSchema\n",
    "spark1.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.RDD'>\n",
      "[[3, 3, 4, 7, 4], [8, 7, 6, 3, 0], [4, 8, 4, 8, 3], [8, 8, 5, 9, 4]]\n",
      "[[3, 3], [4, 7], [4, 8], [7, 6, 3, 0], [4, 8], [4, 8], [3, 8], [8, 5, 9, 4]]\n",
      "20\n",
      "3\n",
      "[3, 3, 4, 7]\n",
      "106\n",
      "106\n",
      "[['These'], ['are'], ['some'], ['of'], ['the'], ['best'], ['Macintosh'], ['computers', 'ever']]\n",
      "These are\n",
      "None some\n",
      "None of\n",
      "None the\n",
      "None best\n",
      "None Macintosh\n",
      "None None\n",
      "[9, 9, 16, 49, 16, 64, 49, 36, 9, 0, 16, 64, 16, 64, 9, 64, 64, 25, 81, 16]\n"
     ]
    },
    {
     "data": {
      "text/plain": "([0, 10, 20, 30, 40, 50, 60, 70, 80, 90], [5, 5, 1, 1, 2, 0, 5, 0, 1])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "import numpy as np\n",
    "# conf = SparkConf().setMaster(\"local[4]\")\n",
    "sc=SparkContext.getOrCreate()\n",
    "lst=np.random.randint(0,10,20)\n",
    "A=sc.parallelize(lst, 4)\n",
    "print(type(A))\n",
    "A.collect()\n",
    "print(A.glom().collect())\n",
    "sc.stop()\n",
    "sc=SparkContext.getOrCreate()\n",
    "A=sc.parallelize(lst)\n",
    "print(A.glom().collect())\n",
    "#sc.stop()\n",
    "print(A.count())\n",
    "print(A.first())\n",
    "print(A.take(4))\n",
    "# A_distinct = A.distinct()\n",
    "# A_distinct.collect()\n",
    "print(A.reduce(lambda x,y: x+y))\n",
    "print(A.sum())\n",
    "words = 'These are some of the best Macintosh computers ever'.split(' ')\n",
    "wordRDD = sc.parallelize(words)\n",
    "print(wordRDD.glom().collect())\n",
    "wordRDD.reduce(lambda w,v: print(w,v))\n",
    "\n",
    "def largerThan(x,y):\n",
    "    \"\"\"\n",
    "    :param x: first element\n",
    "    :param y: second element\n",
    "    :return: returns the last word among the longest words in a list\n",
    "    \"\"\"\n",
    "    if len(x) > len(y):\n",
    "        return x\n",
    "    elif len(y) > len(x):\n",
    "        return y\n",
    "    else:\n",
    "        if x < y: return x\n",
    "        else: return y\n",
    "\n",
    "wordRDD.reduce(largerThan)\n",
    "\n",
    "B = A.map(lambda x: x*x)\n",
    "print(B.collect())\n",
    "B.histogram([x for x in range(0,100,10)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}